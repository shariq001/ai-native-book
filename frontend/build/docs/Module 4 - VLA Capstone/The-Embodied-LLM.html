<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Module 4 - VLA Capstone/The-Embodied-LLM" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">The Embodied LLM: Moving from Chatbots to Robot Controllers | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://shariq001.github.io/ai-native-book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://shariq001.github.io/ai-native-book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://shariq001.github.io/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="The Embodied LLM: Moving from Chatbots to Robot Controllers | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="ChatGPT Can Write a Poem, But Can It Make Coffee?"><meta data-rh="true" property="og:description" content="ChatGPT Can Write a Poem, But Can It Make Coffee?"><link data-rh="true" rel="icon" href="/ai-native-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://shariq001.github.io/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM"><link data-rh="true" rel="alternate" href="https://shariq001.github.io/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM" hreflang="en"><link data-rh="true" rel="alternate" href="https://shariq001.github.io/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"4.1 VLA Model Architecture","item":"https://shariq001.github.io/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM"}]}</script><link rel="stylesheet" href="/ai-native-book/assets/css/styles.7e541338.css">
<script src="/ai-native-book/assets/js/runtime~main.ea3c1e3b.js" defer="defer"></script>
<script src="/ai-native-book/assets/js/main.922eea55.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-native-book/"><div class="navbar__logo"><img src="/ai-native-book/img/logo.png" alt="Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="50" style="height:50px;width:auto"><img src="/ai-native-book/img/logo.png" alt="Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="50" style="height:50px;width:auto"></div><b class="navbar__title text--truncate">AI-Native Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/The-Digital-Nervous-System">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/shariq001/ai-native-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/The-Digital-Nervous-System"><span title="Module 1. The Nervous System" class="categoryLinkLabel_W154">Module 1. The Nervous System</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/The-Digital-Nervous-System"><span title="1.1 Introduction to Middleware" class="linkLabel_WmDU">1.1 Introduction to Middleware</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/Signals-and-Reflexes"><span title="1.2 Communication Patterns" class="linkLabel_WmDU">1.2 Communication Patterns</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/The-Python-Bridge"><span title="1.3 Python Integration" class="linkLabel_WmDU">1.3 Python Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/Defining-the-Body-URDF"><span title="1.4 Robot Description (URDF)" class="linkLabel_WmDU">1.4 Robot Description (URDF)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-native-book/docs/Module 2 - Digital Twin Simulation/The-Mirror-World"><span title="Module 2. The Digital Twin" class="categoryLinkLabel_W154">Module 2. The Digital Twin</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-native-book/docs/Module 3 - AI Robot Brain/Infinite-Training-Data"><span title="Module 3. The AI Brain" class="categoryLinkLabel_W154">Module 3. The AI Brain</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM"><span title="Module 4. Embodied Intelligence" class="categoryLinkLabel_W154">Module 4. Embodied Intelligence</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM"><span title="4.1 VLA Model Architecture" class="linkLabel_WmDU">4.1 VLA Model Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Robot-Ear"><span title="4.2 Speech Processing Pipeline" class="linkLabel_WmDU">4.2 Speech Processing Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Cognitive-Planner"><span title="4.3 LLM-Based Planning" class="linkLabel_WmDU">4.3 LLM-Based Planning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-native-book/docs/Module 4 - VLA Capstone/Capstone-The-Autonomous-Loop"><span title="4.4 Capstone: System Integration" class="linkLabel_WmDU">4.4 Capstone: System Integration</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-native-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4. Embodied Intelligence</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">4.1 VLA Model Architecture</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>The Embodied LLM: Moving from Chatbots to Robot Controllers</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="chatgpt-can-write-a-poem-but-can-it-make-coffee">ChatGPT Can Write a Poem, But Can It Make Coffee?<a href="#chatgpt-can-write-a-poem-but-can-it-make-coffee" class="hash-link" aria-label="Direct link to ChatGPT Can Write a Poem, But Can It Make Coffee?" title="Direct link to ChatGPT Can Write a Poem, But Can It Make Coffee?" translate="no">​</a></h2>
<p>ChatGPT and similar language models can compose poetry, create stories, and engage in sophisticated conversations. But ask them to make a cup of coffee, and they&#x27;re helpless—they don&#x27;t have a body to carry out the task. This is the fundamental difference between &quot;disembodied AI&quot; and &quot;embodied AI.&quot;</p>
<p>An embodied AI doesn&#x27;t just process language—it connects language to physical action in the real world. It experiences the world through sensors and affects the world through actuators, creating a complete loop of perception, reasoning, and action.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="understanding-vla-vision-language-action">Understanding VLA (Vision-Language-Action)<a href="#understanding-vla-vision-language-action" class="hash-link" aria-label="Direct link to Understanding VLA (Vision-Language-Action)" title="Direct link to Understanding VLA (Vision-Language-Action)" translate="no">​</a></h2>
<p>VLA stands for Vision-Language-Action, representing a new class of AI models that go beyond text processing to include:</p>
<ul>
<li class=""><strong>Vision</strong>: Understanding what the robot&#x27;s cameras see</li>
<li class=""><strong>Language</strong>: Processing human commands and instructions</li>
<li class=""><strong>Action</strong>: Controlling the robot&#x27;s movements and manipulations</li>
</ul>
<p>These models are trained on datasets that include not just text, but also robot movements, sensor data, and visual information. Instead of just generating text responses, VLA models generate sequences of actions that robots can execute.</p>
<p>The key breakthrough of VLA models is their ability to understand the connection between language commands and their physical consequences. When told to &quot;move to the red chair,&quot; the model must recognize what red chairs look like in its field of view, understand spatial relationships, and generate the appropriate motor commands to navigate to that location.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="disembodied-vs-embodied-ai">Disembodied vs. Embodied AI<a href="#disembodied-vs-embodied-ai" class="hash-link" aria-label="Direct link to Disembodied vs. Embodied AI" title="Direct link to Disembodied vs. Embodied AI" translate="no">​</a></h2>
<p><strong>Disembodied AI</strong> (like ChatGPT):</p>
<ul>
<li class="">Lives on servers, processing text</li>
<li class="">Has no experience of the physical world</li>
<li class="">Cannot perform physical tasks</li>
<li class="">Limited to generating text responses</li>
<li class="">Trained only on textual data, without understanding physical consequences</li>
<li class="">Excels at linguistic tasks but lacks connection to the physical world</li>
</ul>
<p><strong>Embodied AI</strong> (VLA models):</p>
<ul>
<li class="">Lives in robots, interacting with the physical world</li>
<li class="">Learns from visual input and physical feedback</li>
<li class="">Can perform physical tasks like grasping objects or navigating spaces</li>
<li class="">Processes language to generate motor commands</li>
<li class="">Trained on data that connects language to visual information and physical actions</li>
<li class="">Understands language in the context of real-world interactions</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-translation-challenge-text-tokens-to-motor-torques">The Translation Challenge: Text Tokens to Motor Torques<a href="#the-translation-challenge-text-tokens-to-motor-torques" class="hash-link" aria-label="Direct link to The Translation Challenge: Text Tokens to Motor Torques" title="Direct link to The Translation Challenge: Text Tokens to Motor Torques" translate="no">​</a></h2>
<p>The core challenge in embodied AI is translating abstract language commands into specific physical actions. This requires converting:</p>
<ul>
<li class=""><strong>Text Tokens</strong>: Abstract symbols representing language concepts</li>
<li class=""><strong>Into Motor Torques</strong>: Specific electrical signals that make robot joints move</li>
</ul>
<p>For instance, when you say &quot;Pick up the red cup,&quot; the VLA model must:</p>
<ol>
<li class="">Recognize the red cup in the robot&#x27;s camera feed</li>
<li class="">Plan a path for the robot&#x27;s arm to reach the cup</li>
<li class="">Control the gripper to grasp the cup</li>
<li class="">Execute these movements in the correct sequence</li>
</ol>
<p>This involves multiple subsystems working together: vision models to identify the cup, path planning systems to avoid obstacles, and control systems to move the arm with appropriate force.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="applications-of-vla-models">Applications of VLA Models<a href="#applications-of-vla-models" class="hash-link" aria-label="Direct link to Applications of VLA Models" title="Direct link to Applications of VLA Models" translate="no">​</a></h2>
<p>VLA models are revolutionizing robotics applications by enabling robots to understand natural language commands. This makes robots more accessible to non-expert users, as they can simply speak to a robot rather than programming specific motion sequences.</p>
<p>Common applications include home assistance, warehouse automation, and collaborative manufacturing. In these settings, the ability to understand nuanced language commands like &quot;pick up the fragile blue item near the window&quot; greatly increases robot versatility.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaway">Key Takeaway<a href="#key-takeaway" class="hash-link" aria-label="Direct link to Key Takeaway" title="Direct link to Key Takeaway" translate="no">​</a></h2>
<p>VLA models bridge the gap between language understanding and physical action, enabling robots to follow human commands by translating text into motor torques. This represents a shift from disembodied chatbots to embodied agents that can interact with the physical world. The integration of vision, language, and action in a unified model architecture enables intuitive human-robot interaction.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-native-book/docs/Module 3 - AI Robot Brain/Walking-Not-Rolling"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">3.4 Bipedal Control Dynamics</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Robot-Ear"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">4.2 Speech Processing Pipeline</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#chatgpt-can-write-a-poem-but-can-it-make-coffee" class="table-of-contents__link toc-highlight">ChatGPT Can Write a Poem, But Can It Make Coffee?</a></li><li><a href="#understanding-vla-vision-language-action" class="table-of-contents__link toc-highlight">Understanding VLA (Vision-Language-Action)</a></li><li><a href="#disembodied-vs-embodied-ai" class="table-of-contents__link toc-highlight">Disembodied vs. Embodied AI</a></li><li><a href="#the-translation-challenge-text-tokens-to-motor-torques" class="table-of-contents__link toc-highlight">The Translation Challenge: Text Tokens to Motor Torques</a></li><li><a href="#applications-of-vla-models" class="table-of-contents__link toc-highlight">Applications of VLA Models</a></li><li><a href="#key-takeaway" class="table-of-contents__link toc-highlight">Key Takeaway</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Modules</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ai-native-book/docs/Module 1 - ROS 2 Nervous System/The-Digital-Nervous-System">1. The Nervous System</a></li><li class="footer__item"><a class="footer__link-item" href="/ai-native-book/docs/Module 2 - Digital Twin Simulation/The-Mirror-World">2. The Digital Twin</a></li><li class="footer__item"><a class="footer__link-item" href="/ai-native-book/docs/Module 3 - AI Robot Brain/Infinite-Training-Data">3. The AI Brain</a></li><li class="footer__item"><a class="footer__link-item" href="/ai-native-book/docs/Module 4 - VLA Capstone/The-Embodied-LLM">4. Embodied Intelligence</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">My Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/muhammad---shariq" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/mu_shariq01" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/shariq001/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://my-personal-portfolio-eight-delta.vercel.app/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Portfolio<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 AI-Native Robotics Textbook. All Rights Reserved Muhammad Shariq.</div></div></div></footer></div>
</body>
</html>